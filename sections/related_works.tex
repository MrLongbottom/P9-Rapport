\section{Related Work}\label{sec:related-works}
In this section, we investigate existing literature concerning \gls{lda} and similar topic models, as well as relevant work related to random walk.

\citet{lda} describes \acrlong{lda}, a generative statistical model, which is widely used within the field of topic modeling. 
The intuition behind the \gls{lda} topic model is that a document has an underlying distribution of topics, and that the words of a document are based on these topics.
We provide an overview of this model in \autoref{sec:lda}.

There also exists a large amount of extensions to \gls{lda}.
\citet{blei2012topicmodels} describes some of the most significant extensions that are made from relaxing the assumptions of \gls{lda}.
An extension to the \gls{lda} is the dynamic topic model\cite{blei2006dynamic} which assumes that topics change over time, and thus respects the order of the documents. 
The correlated topic model\cite{blei2007correlated} and pachinko allocation model\cite{li2006pachinko} are other variations of the \gls{lda} which each allow correlations to exist between topics.


\citet{quanti} describes a method of how to quantitatively preprocess and analyze large amounts of journalistic data dating from 1945-2000. 
They propose \gls{lda} as a way of categorizing articles and use this as the basis for search.
However, they only check for a single subject, namely the nuclear topic.  


\citet{Tang2008} successfully combine the two research fields of Topic Modeling and Random Walk search. 
Though their focus is mainly on mapping author and venue relations as part of their topic model, their methods for combining these two fields are still novel and generally applicable.


\citet{yang2009topic} present a method for doing the topic-level random walk to search scientific articles.
They combine their method with various other \gls{ir} methods, such as a \gls{lm}, which they introduce.
They also describe various combinations of \gls{lda} and PageRank.
These combinations are evaluated against information retrieval baselines such as BM25\cite{bm251996}.


This paper is largely based on the work of \citeauthor{yang2009topic}\cite{yang2009topic} and \citeauthor{Tang2008}\cite{Tang2008}.
However, the novelty in this paper comes from a different focus as described by our goals in \autoref{sec:intro}.
Our method will have the significant change of working with a new dataset consisting of documents without explicit connections between documents, which introduces a challenge in using \gls{pr} effectively.
We also evaluate \gls{ir} performance based on queries generated from our dataset.

%Articles, we might want in our related works section:
%\begin{itemize}
%	\item \cite{lda} (written)
%	\item \cite{ClusterPageRank} (written)
%	\item \cite{Tang2008} (written)
%	\item \cite{jelodar2019latent}
%\end{itemize}
