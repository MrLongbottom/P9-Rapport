\section{Experiments}\label{sec:experiment}

The goal of our experiment is to test the quality of various \gls{ir} models and combinations of \gls{ir} models.

We test various combinations of the following baselines:
\begin{itemize}
	\item \gls{lm}
	\item \gls{lda}
	\item \gls{bm25}
	\item \gls{tf-idf}
	\item \gls{pr}
	\item \gls{ppr}
\end{itemize}
\todo[inline]{clarify the difference between lda and this ir method based on lda. Maybe calling it reverse lda or something?}
\todo[inline]{add a small description of each baseline, especially the ones not described earlier in the paper}

Each baseline will be given a query and based on that query produce a document-value vector with one value for each document indicating the relevance of the document based on the query.
Our evaluation results are based on the ranking order of these values.
When multiple baselines are combined, their document-value vector are normalized and then added or multiplied together element-wise.
However, in this experiment we will not only test the ability to retrieve a specfic document based on a query related to the document, but also the ability to retrieve relevant documents within a specific topic, generated by our topic model.

For each baseline we evaluate the quality of it's \gls{ir} for both queries generated based on documents and queries generated based on topics.
For topic queries, all documents with values higher than the mean value in the topic's vector in the document-topic matrix $\theta_t$ are considered correct retrivals.
This also means that while document queries always only have one ground truth positive, topic queries can have several thousands (~1.000-10.000).
This makes them hard to compare on a single baseline, however it is still possible to compare these two results between multiple baselines.

For evaluation metrics/measures we use \gls{map} and $p @ n$.
Each of these metrics are shown as the mean value for 80 queries of length 1 to 4, making a total of 320 queries.

Specifially we hope to see whether \gls{lda} is able to improve the topic \gls{ir} when combined with other baselines and whether \gls{pr} algorithms operating on a graph build based on topic similarity is able to improve any results when combined with other baselines.


\subsection{Hyperparameters}\label{subsec:hyperparameters}
Before setting up our experiment, we did some initial testing to find acceptable hyperparameter values for our \gls{lda} model.
% runtime parameters
First, we adjusted parameters that had to do with how the algorithms run to ensure that the model converged, without spending unnecessary resources.
\texttt{passes} adjusts how many times the model passes over the whole corpus, and can be seen as an 'epoch'. 
This is necessary for smaller datasets to ensure convergence before the algorithm finishes, but for large enough datasets this parameter can have a value of 1, as is the case for \cite{blei2010online} where their corpus includes 3.3M documents, where our dataset is $\sim$32000 documents.
\texttt{iterations} which adjusts the maximum number of iterations of the E-step (from \cite{}, Algorithm 2)\todo{cite} that are allowed without all documents having converged. 
Setting this to a high value ensures convergence, but also increases training time. 
In practice, iterations should be set to the lowest possible values where nearly all (> 99\%) documents have converged by the end of the training.
From testing we found 20 \texttt{passes} and 100 \texttt{iterations} was enough to converge 27678 out of 27919 documents (99.14\%).

% model parameters
Once we had assured convergence of our model, we tested hyperparameters for our \gls{lda} model.
These include:
\begin{itemize}
	\item K - the number of topics
	\item $\alpha$ - dirichlet prior for document-topic distributions
	\item $\eta$ - dirichlet prior for topic-word distributions
\end{itemize}
Similar to clustering algorithms, there is usually an optimal setting for K, where all values above will produce topics that are subtopics of the optimal topics, and all values below will achieve subpar performance.
This theoretical optimal value is however based on the corpus, so tests are needed to find some setting of K that is close to the optimal.
$\alpha$ and $\eta$ adjusts the Dirichlet distributions, which will create the multinomial distributions for document-topic and topic-word relations, respectively.
Lower values will lead to more uneven distributions, favoring fewer topics per document and fewer words per topic, while higher values will make the distribution more uniform.

To find the optimal hyperparameter values we did two sequential grid-searches using the hyperparameter values shown in \autoref{tab:params}.
The first grid-search used the values for $K_1$, while the second used the $K_2$ values.
In both grid-searches the same $\alpha$ and $\eta$ values are used.
To evaluate the \gls{lda} models, we measured perplexity \todo{explain perplexity}\todo{and explain how we choose our model by hand}.
During the first grid-search, we found that $10$ and $50$ were clearly the best values for K.
However, $\alpha$ and $\eta$ values showed no clear favorite.
For the second grid-search we choose more specific K values, to narrow the search, while keeping the $\alpha$ and $\eta$ values the same.
\todo[inline]{add graphs from gridsearches}

Based on manual inspection and evaluation of topics generated by the second grid-search we choose $K = 30$, $\alpha = 0.1$, and $\eta = 0.1$ as the hyperparameters for the final \gls{lda} model.
A new model is generated using these values and this model will be used for the whole experiment.

\begin{table}[h]
	\centering
	\begin{tabular}{c|c}
		Parameter & Tested Values\\
		\hline
		$K_1$ & 10, 50, 100, 200, 300\\
		$K_2$ & 5, 10, 15, 20, 25, 30, 35, 40, 45, 50\\
		$\alpha$ & 0.5, 0.1, 0.01, 0.001\\
		$\eta$ & 0.1, 0.01, 0.001, 0.0001\\
	\end{tabular}
	\caption{Tested hyperparameter values. $K_1$ is the $K$ values used for the first hyperparameter test, while $K_2$ is the $K$ values used for the second hyperparameter test.}
	\label{tab:params}
\end{table}


\subsection{Results}\label{subsec:results}

Results are shown on \autoref{tab:results}, \autoref{tab:results_precision_at_10}, and \autoref{tab:hit_results}.

\begin{table*}[h]
	\centering
	\caption{Results table}
	\begin{tabular}{l|c|c|c|c|c|c|c|c}
		Model / \gls{map} & D1 & D2 & D3 & D4 & T1 & T2 & T3 & T4 \\
		\midrule
		\gls{lda} & 0.00457 & 0.00527 & 0.0429 & 0.0538 & 0.155 & 0.186 & 0.168 & 0.178 \\
		\gls{lm} & 0.198 & 0.152 & 0.291 & 0.260 & 0.126 & 0.130 & 0.128 & 0.129 \\
		\gls{bm25} & 0.270 & 0.656 & 0.866 & \textbf{0.908} & 0.155 & 0.158 & 0.155 & 0.161 \\
		\gls{tf-idf} & 0.210 & 0.621 & 0.799 & 0.897 & 0.155 & 0.157 & 0.155 & 0.161 \\
		\gls{lda} + \gls{pr} & 0.00458 & 0.00526 & 0.0429 & 0.0538 & 0.162 & \textbf{0.195} & \textbf{0.177} & \textbf{0.187} \\
		\gls{lda} * \gls{pr} & 0.00781 & 0.00569 & 0.0410 & 0.0537 & 0.156 & 0.186 & 0.168 & 0.179 \\
		\gls{lm} + \gls{lda} & 0.0419 & 0.0214 & 0.0602 & 0.120 & 0.147 & 0.163 & 0.145 & 0.146 \\
		\gls{lm} * \gls{lda} & 0.0931 & 0.0462 & 0.175 & 0.177 & 0.150 & 0.175 & 0.155 & 0.166 \\
		\gls{lm} + \gls{pr} & 0.170 & 0.153 & 0.283 & 0.256 & 0.130 & 0.132 & 0.130 & 0.131 \\
		\gls{lm} * \gls{pr} & 0.163 & 0.138 & 0.259 & 0.236 & 0.130 & 0.133 & 0.129 & 0.130 \\
		\gls{bm25} + \gls{pr} & 0.269 & 0.656 & 0.866 & 0.902 & \textbf{0.192} & 0.193 & 0.175 & 0.183 \\
		\gls{bm25} * \gls{pr} & 0.267 & \textbf{0.663} & \textbf{0.884} & 0.904 & 0.155 & 0.159 & 0.155 & 0.161 \\
		\gls{bm25} + \gls{lda} + \gls{pr} & \textbf{0.276} & 0.525 & 0.589 & 0.366 & 0.162 & 0.192 & 0.176 & 0.184 \\
		\gls{bm25} * \gls{lda} * \gls{pr} & 0.150 & 0.266 & 0.446 & 0.381 & 0.155 & 0.159 & 0.156 & 0.163 \\
	\end{tabular}
	
	\label{tab:results}
\end{table*}


\begin{table*}[h]
	\centering
	\caption{Results table}
	\begin{tabular}{l|c|c|c|c||c|c|c|c}
		Model / P@10 || P@100 & T1 & T2 & T3 & T4 & T1 & T2 & T3 & T4\\
		\midrule
		\gls{lda} & 0.02 & 0.103 & 0.13 & 0.203 & 0.062 & 0.131 & 0.164 & 0.191 \\
		\gls{lm} & 0.126 & 0.118 & 0.116 & 0.069 & 0.090 & 0.092 & 0.087 & 0.093\\
		\gls{bm25} & 0.136 & 0.161 & 0.164 & 0.174 & 0.142 & 0.165 & 0.175 & 0.151\\ 
		\gls{tf-idf} & 0.16 & 0.125 & 0.2 & 0.148 & 0.163 & 0.169 & \textbf{0.188} & 0.170 \\
		\gls{lda} + \gls{pr} & 0.0188 & 0.103 & 0.141 & \textbf{0.211} & 0.062 & 0.131 & 0.175 & \textbf{0.198} \\
		\gls{lda} * \gls{pr} & 0.0125 & 0.100 & 0.133 & 0.200 & 0.062 & 0.132 & 0.167 & 0.192 \\
		\gls{lm} + \gls{lda} & 0.02 & 0.101 & 0.136 & 0.196 & 0.060 & 0.129 & 0.161 & 0.188  \\
		\gls{lm} * \gls{lda} & 0.02 & 0.085 & 0.109 & 0.161 & 0.055 & 0.114 & 0.129 & 0.152 \\
		\gls{lm} + \gls{pr} & 0.138 & 0.130 & 0.116 & 0.0763 & 0.110 & 0.108 & 0.097 & 0.098 \\
		\gls{lm} * \gls{pr} & 0.148 & 0.128 & 0.116 & 0.0963 & 0.110 & 0.112 & 0.101 & 0.101 \\
		\gls{lm} + \gls{lda} + \gls{pr} & 0.019 & 0.101 & 0.134 & 0.195 & 0.061 & 0.129 & 0.163 & 0.187\\
		\gls{lm} * \gls{lda} * \gls{pr} & 0.026 & 0.090 & 0.110 & 0.161 & 0.059 & 0.115 & 0.130 & 0.152\\
		\gls{bm25} + \gls{pr} & 0.135 & 0.163 & 0.165 & 0.173 & \textbf{0.155} & 0.165 & 0.176 & 0.151 \\
		\gls{bm25} * \gls{pr} & \textbf{0.165} & \textbf{0.169} & \textbf{0.184} & 0.170 & 0.148 & \textbf{0.177} & 0.186 & 0.161\\
		\gls{bm25} + \gls{lda} & 0.124 & 0.160 & 0.154 & 0.204 & 0.113 & 0.155 & 0.168 & 0.198 \\
		\gls{bm25} * \gls{lda} & 0.09 & 0.139 & 0.175& 0.206 & 0.134 & 0.170 & 0.174 & 0.187 \\
		\gls{bm25} + \gls{lda} + \gls{pr} & 0.124 & 0.160 & 0.154 & 0.204 & 0.113 & 0.155 & 0.17 & \textbf{0.198}\\
		\gls{bm25} * \gls{lda} * \gls{pr} & 0.095 & 0.141 & 0.176 & 0.206 & 0.135 & 0.174 & 0.174 & 0.188\\
	\end{tabular}
	
	\label{tab:results_precision_at_10}
\end{table*}


\begin{table}[h]
	\centering
	\caption{Average rank of relevant document for document-queries.}
	\begin{tabular}{l|c|c|c|c}
		Model / Avg. rank & D1 & D2 & D3 & D4 \\
		\midrule
		\gls{lda} & 2287.93 & 1599.95 & 1241.18 & 1926.78 \\
		\gls{lm} & 7120.04 & 9082.9 & 6501.85 & 7782.65 \\
		\gls{bm25} & \textbf{19.58} & 7.94 & 1.78 & 1.41 \\
		\gls{tf-idf} & 30.0 & 9.3 & 2.03 & 1.29 \\
		\gls{lda} + \gls{pr} & 2491.31 & 1342.53 & 1126.23 & 1906.76\\
		\gls{lda} * \gls{pr} & 2305.04 & 1600.93 & 1223.14 & 1920.175\\
		\gls{lm} + \gls{lda} & 1971.19 & 1192.91 & 1027.95 & 1482.69 \\
		\gls{lm} * \gls{lda} & 1874.81 & 1456.21 & 954.66 & 1853.44 \\
		\gls{lm} + \gls{pr} & 7299.85 & 9134.81 & 6429.24 & 7725.36 \\
		\gls{lm} * \gls{pr} & 7328.7625 & 9137.23 & 6504.85 & 7772.4\\
		\gls{lm} + \gls{lda} + \gls{pr} & 1978.74 & 1179.21 & 994.91 & 1438.88 \\
		\gls{lm} * \gls{lda} * \gls{pr} & 1892.12 & 1453.56 & 941.4 & 1850.43 \\
		\gls{bm25} + \gls{lda} & 30.45 & 28.59 & 17.7 & 23.76 \\
		\gls{bm25} * \gls{lda} & 163.76 & 557.13 & 297.48 & 1159.33 \\
		\gls{bm25} + \gls{pr} & 19.69 & \textbf{7.88} & 1.79 & 1.43\\
		\gls{bm25} * \gls{pr} & 23.96 & 8.45 & \textbf{1.61} & \textbf{1.24}\\
		\gls{bm25} + \gls{lda} + \gls{pr} & 30.35 & 28.44 & 17.65 & 23.76\\
		\gls{bm25} * \gls{lda} * \gls{pr} & 163.5 & 555.35 & 295.69 & 1158.08\\
	\end{tabular}
	
	\label{tab:hit_results}
\end{table}