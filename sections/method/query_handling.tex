\section{Search Query}
We have identified three steps when working with a search query:
\begin{itemize}
	\item Generation
	\item Expansion
	\item Handling
\end{itemize}

We will describe each step in the following sections.

\subsection{Query Generation}
We use two techniques for generating the queries used for evaluating our search algorithm, namely document-queries and topic-queries.
The idea behind these two methods is to evaluate the specificity and generality of the \gls{lda} model, respectively.
The construction of the queries is described in the following.

\subsubsection{Document query}
To construct a document query, we randomly select a document from the corpus and a query length $ql$ between $ql_{min}$ and $ql_{max}$.
From this selection, we apply \gls{tf-idf} on the selected document to find the most informative words.
Our query is then the highest $ql$ ranked words within the given document.
The goal is to check whether or not the model is able to find a specific document based on a search query generated from that document.

\subsubsection{Topic query} 
The topic query is slightly different in comparison to document query in that it focuses on the topics rather than a specific document.
To construct a topic query, firstly we select a random topic $t$ and a query length $ql$ between $ql_{min}$ and $ql_{max}$.
We then sample $ql$ documents based on the document-topic distribution $\theta_t$ provided by the \gls{lda} model.
Though $theta$ is normally one topic distribution for each document, we create document distributions for each topic by row normalizing the matrix. 
When sampling these documents, we only sample within the document-topic distribution where the topic is set to $t$.
From these documents, we extract one word from each document and add these to the query based on the \gls{tf-idf} score.
If an extracted word is in the query already, we skip it and add the next highest \gls{tf-idf} score to the query.
In that way, we ensure to get unique words in the query.


\subsection{Query Expansion}
Query expansion is a method which adds more words to a given query to add more context to the search process.
\citet{yang2009topic} describes a query expansion method, called window query expansion.
Queries are expanded based on the neighboring words in the document set.
Specifically, for each word in the query, we count the frequency of each word appearing before and after the given word in the corpus.
We then add top $m$ most frequent words to the query.
An example of this could be the query: 
\begin{quote}
	Query = "Football"
\end{quote}
As an example the most frequent words before and after "Football" in our document set could be:
\begin{itemize}
	\item Coach - 15
	\item Match - 10
	\item Ball - 5
\end{itemize}
A resulting expanded query with an $m$ = 2 would then be:
\begin{quote}
	Query = "Football Coach Match"
\end{quote}



\subsection{Query Handling}
Searching for a given document in a whole data set of documents can be a challenge. 
In this setting, we propose to use the topic distributions of each document for searching.
The search process consists of multiple steps before we are able to use a query within the PageRank algorithm. 
We start with a search query consisting of words which are stemmed.
For each word in the query, we check whether our model knows the word.
If it is known, we use the $\beta$ distribution given by the model for the given word. 
If it is not known, we let the model predict the topic distribution for the given word.
We take the average of these distributions and calculate the Jenson-Shannon distance between this distribution and all other document-topic distributions to figure out which articles are the most similar to the given query.
The final vector has the length of the number of documents and has a value from zero to one in all cells, which describes how similar a query is to the given documents based on the topics.
We then use the resulting vector as our personalization vector for a cluster-based random walk, when searching/ranking articles.
 
