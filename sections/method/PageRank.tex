\section{PageRank}\label{sec:pagerank}
We construct a graph over our documents, where edges between documents $d_i$ and $d_j$ are based on the similarity between them $sim(d_i, d_j)$.

This allows us to use PageRank on the graph to search for similar documents.
On top of this, we can add a personalization vector, to guide the search in a specific direction.
We can base this personalization vector on a search query to find documents similar to the query.

To construct the adjacency matrix for the graph, we apply a similarity function on each pair of document-topic distributions $\theta_{d_i}, \theta_{d_j}$, from our topic model.

We use Jenson-Shannon distance as our similarity function, which is a measure of the distance between probability distributions\cite{jensen-shannon2003}\cite{jensen-shannondis2003}.
It is calculated using the square root of the Jenson-Shannon divergence between two probability distributions and gives a score from 0 to 1.
However since Jenson-Shannon calculates difference rather than similarity, a low value means more similarity, making our similarity function:
$$sim(d_1, d_2) = 1 - JS(\theta_{d_1}, \theta_{d_2})$$


%\subsection{Clustering PageRank}
%
%In \cite{ClusterPageRank}, they describe the \gls{Cluster-CMRW} which is a new version of the random walk model. 
%They improve upon this model by incorporating information from clusters. 
%The clusters are found by employing three different clustering algorithms.
%They create a new transition probability matrix where the cluster information is added by combining three similarity functions based on the information levels present in the data.
%They describe three similarity levels between:
%\begin{itemize}
%    \item Sentence to Sentence - $f(v_i \rightarrow v_j)$
%    \item Sentence to Topic Cluster - $\omega(v_i, clus(v_i))$
%    \item Topic Cluster to Document Set - $\pi(clus(v_i))$
%\end{itemize}
%where $v_i$ is the given sentence and $clus(v_i)$ is the cluster that $v_i$ belongs to.
%
%We want to use this method to incorporate the information given by the topic distributions within a \gls{Cluster-CMRW}. 
%We first create three similarity functions to incorporate topic cluster level information into a new adjacency matrix.
%\begin{itemize}
%    \item Document to Document - $f(d_i \rightarrow d_j)$
%    \item Document to Topic Cluster - $\omega(d_i,clus(d_i))$
%    \item Topic Cluster to Document Set - $\pi(clus(d_i))$
%\end{itemize}
%
%\noindent
%Where $d$ is a document, $clus(d_i)$ is a topic cluster of document $d_i$.
%Notice that a document $d$ can contain multiple topics, as opposed to normal clustering where each element is generally assumed to only be part of one cluster.
%
%\subsection*{Document to Document Similarity}
%As in \autoref{sec:pagerank} we use Jensen-Shannon distance as our base for document-to-document similarity:
%$$ f(d_i \rightarrow d_j) = 1 - JS(d_i, d_j)$$ 
%
%\subsection*{Document to Topic Cluster Similarity}
%We define the similarity between a document and a topic cluster as the document-topic probability distribution between them.
%$$ \omega(d_i,clus(d_i)) = \theta_{d_i,clus(d_i)}$$
%where $\theta$ is the document-topic distribution matrix.
%
%\subsection*{Topic Cluster to Document Set Similarity}
%We define the similarity between a topic $t$ and the whole document set as:
%$$ \pi(clus(d_i)) = \frac{\sum_{d}^{D} \theta_{clus(d_i)}}{D} $$
%where $D$ is the number of documents in the document set.
%
%
%To create the adjacency matrix, \cite{ClusterPageRank} linearly combine the different similarity functions, in which we intend to do the same.
%Formally, the adjacency matrix is calculated with the following function.
%$$ f(d_i \rightarrow d_j | clus(d_i), clus(d_j)) $$
%which is evaluated to 
%
%\begin{align*}
%&f(d_i \rightarrow d_j | clus(d_i), clus(d_j)) = \\
%&f(d_i, d_j) \cdot (\lambda \cdot \pi(clus(d_i))) \cdot \omega(d_i, clus(d_i)) \\ 
%&+ (1-\lambda) \cdot \pi(clus(d_j)) \cdot \omega(d_j, clus(d_j))
%\end{align*}
%
%where $\lambda$ is a weight between $[0,1]$ that controls the relative contribution of the two clusters.
