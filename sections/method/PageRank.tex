\section{PageRank}\label{sec:pagerank}
\gls{pr} is a recursive ranking algorithm, used to rank nodes in a graph.
It is based on the random surfer model, where several surfers would take $s$ amount of steps across a graph.
The number of surfers standing on a given node would be the resulting score for that node.
The \gls{pr} algorithm is defined as follows (expressed in matrix form) \cite{ClusterPageRank}.
$$ \overrightarrow{s} = \mu \widetilde{M}^T \overrightarrow{s} + \frac{(1-\mu)}{|D|} \overrightarrow{e} $$  
where $\overrightarrow{s}$ is a vector consisting of scores for each document. 
$\mu$ is the dampening factor which is set to $0.85$.
$\widetilde{M}^T$ is the adjacency matrix transposed.
$|D|$ is the number of documents.
$\overrightarrow{e}$ is a column vector where all elements are equal to 1.

We construct a graph over our documents, where edges between documents $d_i$ and $d_j$ are based on the similarity between them $sim(d_i, d_j)$.
We run the \gls{pr} algorithm for 20 iterations.
This allows us to use \gls{pr} on the graph to search for similar documents.
To construct the adjacency matrix for the graph, we apply a similarity function on each pair of document-topic distributions $\theta_{d_i}, \theta_{d_j}$, from our topic model.

We use Jensen-Shannon distance as our similarity function, which is a measure of the distance between probability distributions\cite{jensen-shannon2003}\cite{jensen-shannondis2003}.
It is calculated using the square root of the Jensen-Shannon divergence between two probability distributions and gives a score from 0 to 1.
However since Jensen-Shannon calculates difference rather than similarity, a low value means more similarity, making our similarity function:
$$sim(d_1, d_2) = 1 - JS(\theta_{d_1}, \theta_{d_2})$$

The Jensen-Shannon distance function is defined as:
$$ JS = \frac{D(p || m) + D(q || m)}{2}$$
where $p$ and $q$ are distributions and $m$ is the pointwise mean between $p$ and $q$. 
$D$ is the Kullback-Leibler divergence function.

The goal of using \gls{pr} is to get the most important documents within a specific topic and use these to yield important information during search.  
