\section{Cluster-based Random Walk}
To perform random walk on a document set, such as Nordjyske, probabilities of jumping between documents is needed to perform each step.
We have chosen to use a similarity measure between each document as these probabilities.
This is calculated by using the document-topic distributions from the \gls{lda}.
These distributions can be arranged in a matrix $\theta$, which is described later.

In \cite{ClusterPageRank}, they describe the \gls{Cluster-CMRW} which is a new version of the random walk model. 
They improve upon this model by incorporating information from clusters. 
The clusters are found by employing three different clustering algorithms.
They create a new transition probability matrix where the cluster information is added by combining three similarity functions based on the information levels present in the data.
They describe three similarity levels between:
\begin{itemize}
    \item Sentence to Sentence - $f(v_i \rightarrow v_j)$
    \item Sentence to Topic Cluster - $\omega(v_i, clus(v_i))$
    \item Topic Cluster to Document Set - $\pi(clus(v_i))$
\end{itemize}
where $v_i$ is the given sentence and $clus(v_i)$ is the cluster that $v_i$ belongs to.

We want to use this method to incorporate the information given by the topic distributions within a \gls{Cluster-CMRW}. 
We first create three similarity functions to incorporate topic cluster level information into a new adjacency matrix.
\begin{itemize}
    \item Document to Document - $d2d(d_1 \rightarrow d_2)$
    \item Document to Topic Cluster - $d2t(d,t)$
    \item Topic Cluster to Document Set - $t2D(t)$
\end{itemize}
\todo[inline]{Overvej at være konsistente i brugen af t/topics og clusters, for at forbedre forståeligheden af den længere ligning på 37+ pt.. Hvordan det præcis skal gøres er ikke bestemt. Det kan muligvis indebære at der gøres så der ikke springes mellem topics og topic clusters igennem afsnittet.}

\noindent
Where $d$ is a document, $t$ is a topic.
Notice that a document $d$ can contain multiple topics, as opposed to normal clustering where each element is generally assumed to only be part of one cluster.
These similarity functions are described in detail in \autoref{sec:similarity}.

To create the adjacency matrix, \cite{ClusterPageRank} linearly combine the different similarity functions, in which we intend to do the same.
Formally, the adjacency matrix is calculated with the following function.
$$ f(d_1 \rightarrow d_2 | clus(d_1), clus(d_2)) $$
which is evaluated to 

\begin{align*}
&f(d_1 \rightarrow d_2 | clus(d_1), clus(d_2)) = \\
&d2d(d_1, d_2) \cdot (\lambda \cdot t2D(clus(d_1))) \cdot d2t(d_1, clus(d_1)) \\ 
&+ (1-\lambda) \cdot t2D(clus(d_2)) \cdot d2t(d_2, clus(d_2))
\end{align*}
where $\lambda$ is a weight between $[0,1]$ that controls the relative contribution of the two clusters.


\section{Similarity Measures}\label{sec:similarity}
\subsection{Similarity between two documents}
The matrix $\theta$ describes the topic distribution for each document $d \in M$, where $\theta_d$ is the topic distribution for document $d$, and is a $K$-dimensional vector that sums to 1, where $K$ is the number of topics. \todo[inline]{Tjek at M er defineret når LDA afsnittet merges.}
The similarity between two documents $d_1$ and $d_2$ is defined as:
$$ d2d(d_1, d_2) = \sum_{1}^{K} min(\theta_{d_1,k}, \theta_{d_2,k})$$

\subsection{Similarity between documents and topic clusters}
We define the similarity between a document and a topic cluster as the document-topic probability distribution between them.
$$ d2t(d,t) = \theta_{d,t}$$

\subsection{Similarity measure between topic clusters and the whole document set}
We define the similarity between a topic $t$ and the document set $D$ as:
$$ t2D(t, D) = \frac{\sum_{d}^{M} \theta_{d,t}}{M} $$
